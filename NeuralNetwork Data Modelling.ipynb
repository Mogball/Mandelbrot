{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import numpy as np\n",
    "\n",
    "class NeuralNetwork(object):\n",
    "    \n",
    "    def __init__(self, L, Lambda = 0):\n",
    "        # L is the array describing the hyperparameters\n",
    "        # L = [inputs, hidden1, hidden2, ..., outputs]\n",
    "        self.L = L\n",
    "        \n",
    "        # Initialize each hidden layer\n",
    "        self.W = []\n",
    "        \n",
    "        # For each hidden layer hyperparameter, assign random weights\n",
    "        for w in range(0, len(L) - 1):\n",
    "            self.W.append(np.random.randn(self.L[w], self.L[w+1]))\n",
    "        \n",
    "        # The regularization coefficient\n",
    "        self.Lambda = Lambda\n",
    "    \n",
    "    def sigmoid(self, z):\n",
    "        # Sigmoid activation function\n",
    "        #vSigmoidFast = np.vectorize(self.sigmoidFast)\n",
    "        #return vSigmoidFast(z)\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "        #return z / (1 + abs(z))\n",
    "        \n",
    "    def sigmoidPrime(self, z):\n",
    "        # Derivative of the sigmoid function\n",
    "        #return np.exp(-z) / ((1 + np.exp(-z)) ** 2)\n",
    "        y = self.sigmoid(z)\n",
    "        return y * (1 - y)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        # Forward propagation of the input signals through the network\n",
    "        # Initialize the weighted inputs and the activations and receive inputs\n",
    "        self.Z = [X]\n",
    "        self.A = [self.Z[0]]\n",
    "        \n",
    "        # Propagate\n",
    "        for n in range(1, len(self.L)):\n",
    "            self.Z.append(self.A[n-1].dot(self.W[n-1]))\n",
    "            self.A.append(self.sigmoid(self.Z[n]))\n",
    "            \n",
    "        # Return the predicted values\n",
    "        yHat = self.A[len(self.L) - 1]\n",
    "        return yHat\n",
    "    \n",
    "    def costFunction(self, X, Y):\n",
    "        # Compute the cost function using the current weights\n",
    "        # Quadratic cost function: sum of the squared errors\n",
    "        self.yHat = self.forward(X)\n",
    "        J = 0.5 * sum((Y - self.yHat) ** 2)\n",
    "        regJ = 0\n",
    "        for w in range(0, len(self.L) - 2):\n",
    "            regJ = regJ + 0.5 * self.Lambda * sum(self.W[w] ** 2)\n",
    "        J = J + regJ\n",
    "        return J\n",
    "    \n",
    "    def costFunctionPrime(self, X, Y):\n",
    "        # Compute the gradient of the cost function over weights\n",
    "        yHat = self.forward(X)\n",
    "        \n",
    "        # Compute the first error\n",
    "        N = len(self.L) - 1 #max layer index\n",
    "        i = N #index pointing to a layer\n",
    "        delta = [np.multiply(yHat - Y, self.sigmoidPrime(self.Z[i]))]\n",
    "        dJdW = [np.dot(self.A[i-1].T, delta[N-i]) + self.Lambda * self.W[i-1]]\n",
    "        i = i - 1\n",
    "        \n",
    "        # Compute the rest of the errors, where the last error is the first in the list\n",
    "        while i > 0:\n",
    "            delta_i = np.dot(delta[N-i-1], self.W[i].T) * self.sigmoidPrime(self.Z[i])\n",
    "            delta.append(delta_i)\n",
    "            dJdW_i = np.dot(self.A[i-1].T, delta_i) + self.Lambda * self.W[i-1]\n",
    "            dJdW.append(dJdW_i)\n",
    "            i = i - 1\n",
    "        \n",
    "        # Return the list of gradients\n",
    "        return dJdW\n",
    "    \n",
    "    # Helper functions\n",
    "    # All assume that there is at least one hidden layer\n",
    "    def getParams(self):\n",
    "        # The set of all parameters or the weights\n",
    "        i = 0\n",
    "        params = np.concatenate((self.W[i].ravel(), self.W[i+1].ravel()))\n",
    "        i = 2\n",
    "        while i < len(self.L)-1:\n",
    "            params = np.concatenate((params, self.W[i].ravel()))\n",
    "            i = i + 1\n",
    "        return params\n",
    "    \n",
    "    def setParams(self, params):\n",
    "        # Set the parameters from the collection of weights\n",
    "        i = 0\n",
    "        start = 0\n",
    "        end = 0\n",
    "        while i < len(self.L)-1:\n",
    "            start = end\n",
    "            end = end + self.L[i] * self.L[i+1]\n",
    "            self.W[i] = np.reshape(params[start:end], (self.L[i], self.L[i+1]))\n",
    "            i = i + 1\n",
    "            \n",
    "    def computeGradients(self, X, Y):\n",
    "        # Compute and return the set of all gradients\n",
    "        dJdW = self.costFunctionPrime(X, Y)\n",
    "        i = len(self.L) - 2\n",
    "        grad = np.concatenate((dJdW[i].ravel(), dJdW[i-1].ravel()))\n",
    "        i = i - 2\n",
    "        while i >= 0:\n",
    "            grad = np.concatenate((grad, dJdW[i].ravel()))\n",
    "            i = i - 1\n",
    "        return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The data parsing function\n",
    "import csv\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "def parseDataFormatted(dataPath):\n",
    "    # Parse data from a comma delimited file\n",
    "    # Output will be correct numpy array representing the data\n",
    "    with open(dataPath, 'rt') as dataFile:\n",
    "        dataReader = csv.reader(dataFile, delimiter = ',')\n",
    "        data = list(dataReader)\n",
    "        \n",
    "        # Parse the data into an array, assuming that the first datum has no issues\n",
    "        X = np.array([[float(data[0][0])]], dtype = float64)\n",
    "        Y = np.array([[float(data[0][1])]], dtype = float64)\n",
    "        for i in range(1, len(data)):\n",
    "            # Ensure that both the x and y values have something in them\n",
    "            # x = entry[0], y = entry[1]\n",
    "            entry = data[i]\n",
    "            if entry[0] and entry[1]:\n",
    "                X = np.append(X, [[float(entry[0])]], axis = 0)\n",
    "                Y = np.append(Y, [[float(entry[1])]], axis = 0)\n",
    "    \n",
    "    # Returned the parsed data\n",
    "    return X, Y\n",
    "\n",
    "def parseData(dataPath, column):\n",
    "    # Parse data from a comma delimited file\n",
    "    # Output will be correct numpy array representing the data\n",
    "    with open(dataPath, 'rt') as dataFile:\n",
    "        dataReader = csv.reader(dataFile, delimiter = ',')\n",
    "        dataReader.__next__()\n",
    "        data = list(dataReader)\n",
    "        data = dateConversion(data)\n",
    "        \n",
    "        # Parse the data into an array, assuming that the first datum has no issues\n",
    "        X = np.array([[float(data[0][0])]], dtype = float64)\n",
    "        Y = np.array([[float(data[0][1])]], dtype = float64)\n",
    "        for i in range(1, len(data)):\n",
    "            # Ensure that both the x and y values have something in them\n",
    "            # x = entry[0], y = entry[1]\n",
    "            entry = data[i]\n",
    "            if entry[0] and entry[1]:\n",
    "                X = np.append(X, [[float(entry[0])]], axis = 0)\n",
    "                Y = np.append(Y, [[float(entry[column])]], axis = 0)\n",
    "    \n",
    "    # Returned the parsed data\n",
    "    return X, Y\n",
    "\n",
    "def dateConversion(data):\n",
    "    for i in range(0, len(data)):\n",
    "        data[i][0] = data[i][0][0:6] + \"20\" + data[i][0][6:]\n",
    "        data[i][0] = time.mktime(datetime.datetime.strptime(data[i][0], \"%m/%d/%Y\").timetuple())\n",
    "    return data\n",
    "\n",
    "# Checks if a string is a number\n",
    "def isFloat(s):\n",
    "    try:\n",
    "        float(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Normalize the values between -1 and 1\n",
    "def normalize(X, Y):\n",
    "    normX = X - np.amin(X, axis = 0)\n",
    "    normY = Y - np.amin(Y, axis = 0)\n",
    "    normX = normX / np.amax(normX, axis = 0)\n",
    "    normY = normY / np.amax(normY, axis = 0)\n",
    "    return normX, normY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import optimize\n",
    "\n",
    "# A class that will handle training the neural network\n",
    "class Trainer(object):\n",
    "\n",
    "    def __init__(self, NN):\n",
    "        # Keep a reference to the neural network that this class will train\n",
    "        self.NN = NN\n",
    "        \n",
    "    # A few helper functions to interface with numpy's optimization library\n",
    "    def callbackFunction(self, params):\n",
    "        self.NN.setParams(params)\n",
    "        self.J.append(self.NN.costFunction(self.X, self.Y))\n",
    "        \n",
    "    def costFunctionWrapper(self, params, X, Y):\n",
    "        self.NN.setParams(params)\n",
    "        cost = self.NN.costFunction(X, Y)\n",
    "        grad = self.NN.computeGradients(X, Y)\n",
    "        return cost, grad\n",
    "    \n",
    "    # Train the neural network\n",
    "    def train(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        # Initialize to an empty cost list\n",
    "        self.J = []\n",
    "        \n",
    "        params0 = self.NN.getParams()\n",
    "        options = {'maxiter': 5000, 'disp': True}\n",
    "        _res = optimize.minimize(self.costFunctionWrapper, params0, jac=True, method='BFGS',\\\n",
    "                                args = (X, Y), options=options, callback=self.callbackFunction)\n",
    "        self.NN.setParams(_res.x)\n",
    "        self.optimizationResults = _res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Variance function of a set\n",
    "def variance(A):\n",
    "    var = 0\n",
    "    mean = A.mean()\n",
    "    for i in range(0, len(A)):\n",
    "        var = var + (A[i] - mean) ** 2\n",
    "    var = var / len(A)\n",
    "    return var\n",
    "\n",
    "# Autocovariance function of a set given a lag\n",
    "def autocovariance(A, h):\n",
    "    acovar = 0\n",
    "    mean = A.mean()\n",
    "    for i in range(0, len(A) - h):\n",
    "        acovar = acovar + (A[i] - mean) * (A[i + h] - mean)\n",
    "    acovar = acovar / len(A)\n",
    "    return acovar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The autocorrelation 0 <= r <= 1 of a set with a given lag\n",
    "def autocorrelation(A, h):\n",
    "    var = variance(A)\n",
    "    acovar = autocovariance(A, h)\n",
    "    r = acovar / var\n",
    "    return r\n",
    "\n",
    "# Evaluate a neural network at a single point\n",
    "def evaluateNetwork(NN, x):\n",
    "    yHat = NN.forward(np.array(x))\n",
    "    return yHat[0][0]\n",
    "\n",
    "# Sample a continuous neural network function at a certain interval\n",
    "def sampleNetwork(NN, delta):\n",
    "    sample = np.array(evaluateNetwork(NN, 0))\n",
    "    for x in np.arange(delta, 1.0 + delta, delta):\n",
    "        sample = np.append(sample, evaluateNetwork(NN, x))\n",
    "    return sample\n",
    "\n",
    "# Sample from a set at an interval\n",
    "def sampleSet(S, delta):\n",
    "    sample = []\n",
    "    for i in np.arange(0, len(S), delta):\n",
    "        sample.append(S[i][0])\n",
    "    return np.array(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Returns the set of primary autocorrelation values for each lag\n",
    "def lagAutocorrelation(sample, maxLag):\n",
    "    R = np.array(autocorrelation(sample, 0), dtype = float64)\n",
    "    for lag in range(1, maxLag):\n",
    "        R = np.append(R, autocorrelation(sample, lag))\n",
    "    return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lag set sampling creates the format necessary for time series prediction\n",
    "def lagSample(Y, lag, forecast, outputs):\n",
    "    # Y: the set from which to create the sample\n",
    "    # lag: the number of values in the X-sample for one value in the Y-sample\n",
    "    # forecast: the number of values between the last X-sample value and\n",
    "    # the Y-sample value\n",
    "    Xs = np.array([Y[0:lag]])\n",
    "    Ys = np.array([Y[lag + forecast:lag + forecast + outputs]])\n",
    "    for i in range(1, len(Y) - lag - forecast - outputs):\n",
    "        Xs = np.append(Xs, [Y[i:i+lag]], axis = 0)\n",
    "        Ys = np.append(Ys, [Y[i+lag+forecast:i+lag+forecast+outputs]], axis = 0)\n",
    "    return Xs, Ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.array([[0.2, 0.5], [0.5, 0.3], [0.4, 0.9], [0.6, 0.7]])\n",
    "Y = np.array([[0.5], [0.2], [0.6], [0.4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000000\n",
      "         Iterations: 46\n",
      "         Function evaluations: 51\n",
      "         Gradient evaluations: 51\n"
     ]
    }
   ],
   "source": [
    "NN = NeuralNetwork([2, 3, 2, 1])\n",
    "T = Trainer(NN)\n",
    "T.train(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "L = NN.costFunctionPrime(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
